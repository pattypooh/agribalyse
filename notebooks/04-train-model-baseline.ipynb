{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import  SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from src.data import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = preprocessing.dict_params\n",
    "INPUT_FILE_PATH = './../data/processed'\n",
    "OUTPUT_FILE_PATH = './../models'\n",
    "INDEX_KEY = [0] # the 1st column is the primary key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'synthese': {'file_name': 'Agribalyse_Synthese.csv', 'keep_cols': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'index_key': [0]}, 'ingredients': {'file_name': 'Agribalyse_Detail ingredient.csv', 'keep_cols': [0, 2, 3, 4, 5, 6, 7], 'index_key': [0], 'pivot_idx_key': [0, 1, 2, 3, 4], 'pivot_idx_col': 5, 'pivot_idx_values': 6, 'pivot_keep_cols': [0, 2, 3, 4, 5, 6, 7]}, 'etapes': {'file_name': 'Agribalyse_Detail etape.csv', 'keep_cols': [0, 8, 9, 10, 11, 12, 13], 'index_key': [0]}}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abats de bœuf', 'Abats de porc', 'Abats de poulet', 'Abats de veau',\n",
       "       'Abricot', 'Ail', 'Amande', 'Amidon de maïs', 'Ananas', 'Anchois',\n",
       "       ...\n",
       "       'max_EF_Viande de moutton sans os', 'max_EF_Viande de porc maigre',\n",
       "       'max_EF_Viande de poulet sans os', 'max_EF_Viande de veau sans os',\n",
       "       'max_EF_Vin blanc', 'max_EF_Vin rouge', 'max_EF_Yaourt',\n",
       "       'max_EF_citron', 'max_EF_Échalote', 'max_EF_Œuf de poule'],\n",
       "      dtype='object', length=639)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_ori = pd.read_csv(os.path.join(INPUT_FILE_PATH, preprocessing.get_param('ingredients', 'file_name')))\n",
    "data_df_ori.columns[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df)->pd.DataFrame:\n",
    "    # Drop columns\n",
    "    drop_cols = ['Code_AGB', 'Code_CIQUAL', 'Groupe_aliment', 'Sous-groupe_aliment', 'Nom_Produit_Francais', 'LCI_Name',\\\n",
    "          'Saisonnalite', 'Transport_par_avion_', 'Livraison', 'Livraison', 'Materiau_emballage', 'Preparation', 'DQR_Note_qualite_la_donnee_']\n",
    "    clean_df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    # Drop lines with no ingredients (all 0)\n",
    "    with_ing=clean_df.iloc[:,1:].sum(axis=1)!=0\n",
    "   \n",
    "    clean_df = clean_df[with_ing].copy()\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = clean_data(data_df_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ingredients kept for training :640\n",
      "Number of products kept for training:1038\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of ingredients kept for training :{len(data_df.columns)}')\n",
    "print(f'Number of products kept for training:{data_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = data_df.dropna(axis=0)\n",
    "y= data_df.loc[:,'Score_unique_EF_'].copy()\n",
    "X= data_df.drop('Score_unique_EF_', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(830, 639)\n",
      "y_train:(830,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train:{X_train.shape}')\n",
    "print(f'y_train:{y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingred_features = X_train.columns.to_list()\n",
    "num_features = X_train.select_dtypes(include=np.number).columns.to_list()\n",
    "cat_features = []\n",
    "\n",
    "# Transformer SVD\n",
    "svd_transformer = Pipeline([\n",
    "    ('svd', TruncatedSVD(n_components=32)),])\n",
    "\n",
    "# transformer for numerical features\n",
    "num_transformer = Pipeline([\n",
    "        ('imputer_num', SimpleImputer(strategy = 'median')),\n",
    "        #('scaler', StandardScaler())\n",
    "    ])\n",
    "# transformer for categorical features\n",
    "cat_transformer = Pipeline([\n",
    "        ('imputer_cat', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('categoricals', cat_transformer, cat_features),\n",
    "        ('numericals', num_transformer, num_features),\n",
    "         ('dim_reduction', svd_transformer, ingred_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Linear Regression model and then predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(pipeline, X_train, y_train):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_train)\n",
    "    print(f'Train - R2 Score: {r2_score(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R2 Score: -9.58912826402481e+21\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = Pipeline([\n",
    "        ('transformation', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "fit_predict(full_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.307030124586982e+22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, full_pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - R2 Score: 0.8642556391040292\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = Pipeline([\n",
    "        ('transformation', preprocessor),\n",
    "        ('random_forest', RandomForestRegressor(max_depth=10))\n",
    "    ])\n",
    "fit_predict(full_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556347238080086"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = full_pipeline.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FOLDER = './../models'\n",
    "#Attention, this is commented because we dont want to recreate the model\n",
    "#joblib.dump(full_pipeline, os.path.join(MODELS_FOLDER, \"score_predictor.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cc47c8831822e32dd5f765150260df6f896d34b43f3e216997ee9b0d9ca468e"
  },
  "kernelspec": {
   "display_name": "kernel-pez-jedha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
